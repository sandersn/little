#lang racket
; alternatively, install MALT fromm the little learner web site
(define tensor vector)
(define tensor? vector?)
; TODO: Should only be: Real Number
(define (scalar? d) 
  (or (number? d) (dual? d)))
(define ref list-ref)
(define tref vector-ref)
(define tlen vector-length)
(define len length)
(define (gradient-of f theta)
  (let ((wrt (map* dual* theta)))
    (gradient-of-once (f wrt) wrt)))
(define (map* f y)
  (cond
    ((scalar? y) (f y))
    ((list? y) (map (lambda (lm) (map* f lm)) y))
    ((vector? y) (vector-map (lambda (ve) (map* f ve)) y))))
(define (dual rho kappa)
  (vector dual rho kappa))
(define (dual? d)
  (and (vector? d) (eq? (vector-ref d 0) dual)))
(define (rho d)
  (cond
    ((dual? d) (vector-ref d 1))
    (else d)))
(define (kappa d)
  (cond
    ((dual? d) (vector-ref d 2))
    (else end-of-chain)))
(define (dual* d)
  (dual (rho d) end-of-chain))
(define (end-of-chain d z sigma)
  (let ((g (hash-ref sigma d 0.0)))
    (hash-set sigma d (+ z g))))
(define (gradient-of-once y wrt)
  (let ((sigma (gradient-of-sigma y (hasheq))))
    (map* (lambda (d) (hash-ref sigma d 0.0)) wrt)))
(define (gradient-of-sigma y sigma)
  (cond
    ((scalar? y)
     (let ((k (kappa y)))
       (k y 1.0 sigma)))
    ((list? y) (gradient-of-sigma-list y sigma))
    ((vector? y) (gradient-of-sigma-vector y sigma))))
(define (gradient-of-sigma-list y sigma)
  (cond
    ((null? y) sigma)
    (else (gradient-of-sigma-list (cdr y) (gradient-of-sigma (car y) sigma))))) 
(define (gradient-of-sigma-vector y i sigma)
  (let ((sigma-hat (gradient-of-sigma (vector-ref y i) sigma)))
    (cond
      ((zero? i) sigma-hat)
      (gradient-of-sigma-vector (sub1 i) sigma-hat))))
(define (trefs t b)
  (list->vector (map (lambda (i) (ref t i)) b)))
(define refr drop)
(define (prim1 rho-fn gradient-fn)
  (lambda (da)
    (let ((rho-a (rho da)))
      (dual (rho-fn rho-a) 
        (lambda (_ z sigma)
          (let ((ga (gradient-fn rho-a z)))
            ((kappa da) da ga sigma)))))))
(define (prim2 rho-fn gradient-fn)
  (lambda (da db)
    (let ((rho-a (rho da))
          (rho-b (rho db)))
      (dual (rho-fn rho-a rho-b) 
        (lambda (_ z sigma)
          (let-values (((ga gb) (gradient-fn rho-a rho-b z)))
            ((kappa db) db gb ((kappa da) da ga sigma))))))))
(define (comparator f)
  (lambda (da db)
    (f (rho da) (rho db))))
(define exp-0 (prim1 exp (lambda (ra z) (* (exp ra) z))))
(define +-0-0 (prim2 + (lambda (ra rb z) (values z z))))
(define --0-0 (prim2 - (lambda (ra rb z) (values z (- z)))))
(define *-0-0 (prim2 * (lambda (ra rb z) (values (* rb z) (* ra z)))))
(define /-0-0 (prim2 / 
                 (lambda (ra rb z) 
                   (values 
                     (* (/ 1 rb) z) 
                     (* (/ (* -1 ra) (* rb rb)) z)))))
(define expt-0-0 (prim2 expt 
                   (lambda (ra rb z) 
                     (values 
                       (* z (* z (expt ra (- rb 1))))
                       (* (* (expt ra rb) (log ra)) z)))))
(define <-0-0 (comparator <))
(define >-0-0 (comparator >))
(define <=-0-0 (comparator <=))
(define >=-0-0 (comparator >=))
(define =-0-0 (comparator =))

(define (tensor-lift f)
  (define (tensor-apply x y)
    (cond
      ((and (scalar? x) (scalar? y)) (f x y))
      ((scalar? x) (vector-map (lambda (y) (tensor-apply x y)) y))
      ((scalar? y) (vector-map (lambda (x) (tensor-apply x y)) x))
      ((and (tensor? x) (tensor? y)) (vector-map tensor-apply x y))))
  tensor-apply)
(define (tensor-lift1 f)
  (define (tensor-apply x)
    (if (scalar? x)
      (f x)
      (vector-map tensor-apply x)))
  tensor-apply)
(define (tensor-lift2 f)
  (define (tensor-apply x)
    (cond
      ((scalar? x) x) ; but is actually not supposed to happen
      ((scalar? (tref x 0)) (f x))
      (else (vector-map tensor-apply x))))
  tensor-apply)
; TODO: The dual versions need to be extended, not the primitives
; TODO: Actually maybe we need both. It's EXTREMELY unclear. I probably need to type all of this.
(define +-* (tensor-lift +))
(define --* (tensor-lift -))
(define *-* (tensor-lift *))
(define sqr-* (tensor-lift1 sqr))
; TODO: Does this need to use the dual version of primitives?
(define (sum-1 tensor)
  (let loop ((i (sub1 (tlen tensor))) (acc 0))
    (if (zero? i)
      (+ acc (tref tensor 0))
      (loop (sub1 i) (+ acc (tref tensor i))))))
(define sum (tensor-lift2 sum-1))
(define (dot-product t u)
  (sum-1 (vector-map * t u)))

(define (line x)
    (lambda (theta) (+-0-0 (*-0-0 (ref theta 0) x) (ref theta 1))))
(define line-xs (tensor 2.0 1.0 4.0 3.0))
(define line-ys (tensor 1.8 1.2 4.2 3.3))

(define (rank tensor)
  (let loop ((acc 0) (t tensor))
    (if (scalar? t)
      acc
      (loop (add1 acc) (tref t 0)))))
(define (shape tensor)
    (let loop ((acc '()) (t tensor))
        (if (scalar? t)
            acc
            (loop (cons (tlen t) acc) (tref t 0)))))
(define (l2-loss target)
  (lambda (xs ys)
    (lambda (theta)
      (let ((pred-ys ((target xs) theta)))
        (sum-1 (sqr-* (--* ys pred-ys)))))))
(define-syntax with-hypers
  (syntax-rules ()
    ((_ ((name value)) body ...)
      (let ((tmp name)) 
       (set! name value)
       (let ((result (begin body ...))) 
         (set! name tmp)
         result)))
    ((_ ((name value) (names values) ...) body ...)
     (let ((tmp name)) 
       (set! name value)
       (let ((result (with-hypers ((names values) ...) body ...))) 
         (set! name tmp)
         result)))))
(define-syntax declare-hyper
  (syntax-rules ()
    ((_ name)
     (define name #f))))
(declare-hyper alpha)
(declare-hyper revs)
(define (revise f revs theta)
  (cond
    ((zero? revs) theta)
    (else (revise f (sub1 revs) (f theta)))))
(define (gradient-descent obj theta)
  (let ((f (lambda (big-theta)
              (map (lambda (p g) (- p (* alpha g))) big-theta (gradient-of obj big-theta)))))
    (revise f revs theta)))
